---
title: "gardon-vignette"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{gardon-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
# installer et charger les donnees du package
library(gardon)

```

1. Créer une base de données unique
--------------------
La première chose à faire est de fusionner les tables d'ASPE pour construire une base de données unique.  
Pour cela, on va utiliser la fonction `getDataRegion()`.   
Cette fonction permet de :   
- fusionner les tables d'ASPE utiles aux test réalisés par la suite.   
- Selectionner les données d'une seule région ou d'un seul departement si nécessaire.  
/!/ Possibilité d'utiliser un jeu de données d'exemple : `exemple_IDF`

```{r, message=FALSE}
data_IDF <- getDataRegion(
  file.name = NULL,
  package.data = TRUE, #utilisation des donnees en exemple
  file.name.mei = NULL,
  station.filter = NULL,
  dir = getwd(),
  region.code.insee = 11, #la region ile de france
  departement.code.insee = NULL,
  echelle = "region",
  date = '2007-01-01', #donnees a partir de 2007
  CRS = 2154, #le crs de la France metropolitaine
  correct.coord = TRUE,
  save = FALSE,
  ecrevisse = FALSE
  )

```

2. Tests à réaliser en priorité
--------------------
Certaines variables seront utilisées par la suite pour vérifier d'autres variables.  
Celles-ci doivent donc être vérifiées en priorité : la largeur de l'opération et la distance   
à la source.  
Pour la largeur, plusieurs méthodes sont disponibles (run `?test_ope_largeur` pour plus   
de détail). Ici nous allons opter pour celle qui identifie les valeurs aberrantes à l'aide de   
l'IQR criterion en groupant les operations par points de prélèvements aux préalables.

```{r Lar_test, message=FALSE, fig.dim=c(7,5)}
result_Lar <- test_ope_Lar(
  data = data_IDF,
  pdf = FALSE,
  csv = FALSE,
  method = 4,
  echelle = "POP")
# preferable de mettre "pdf = TRUE" pour mieux visualiser les figures

```

Configurer de cette manière la fonction renvoie des figures et mais n'enregistre pas   
les résultats sous forme de pdf et d'un fichier csv comprenant le détail des alertes.  
  
En ce qui concerne la distance à la source, deux tests sont disponibles : `test_pop_dist()` qui  
vérifie la cohérence des valeurs et `test_pop_DS()` qui croisent ces valeurs avec celles de  
l'altitude et de la surface du bassin versant. Plus précisement, ce dernier vérifie que l'altitude  
diminue et que la surface du bassin versant augmente bien avec la distance à la source.  

```{r, message=FALSE, fig.dim=c(7,5), warning=FALSE}
result_dist <- test_pop_dist(
  data = data_IDF,
  pdf = FALSE,
  csv = FALSE,
  method = 2)

```
Aucune valeur aberrante n'est identifiée avec cette méthode mais des alertes sont indiquées  
car il y a présence de valeurs manquantes (= NA).  

```{r, message=FALSE, fig.dim=c(7,5)}
result_DS <- test_pop_DS(
  data = data_IDF,
  pdf = FALSE,
  csv = FALSE
  )

```


3. Exemples des possibilités avec les tests
--------------------

### A) Valeurs minimum et maximum
La première possibilité pour tester la cohérence de valeurs quantitatives est de définir un  
interval de valeurs à l'extérieur duquel les valeurs sont considérées comme des valeurs aberrantes.  
Ici on prend l'exemple des valeurs de température extérieure de janvier avec un interval de 4°C à 7°C.

```{r, message=FALSE, fig.dim=c(7,5), warning=FALSE}
result_TempJanv <- test_pop_tempJanv(
  data = data_IDF,
  pdf = FALSE,
  csv = FALSE,
  method = 1,
  min = 4,
  max = 7
  )

```
Cependant cette méthode demande une bonne connaissance des valeurs "plausibles" du paramètre en question.

### B) IQR criterion
La deuxième méthode est celle de l'IQR criterion. L'IQR (Interquartile Range) correspond à l'écart entre  
le premier quartile (Q1) et le troisième quartile (Q3). Cette méthode va donc considérer que toute valeur supérieure à `Q3 + (1.5 * IQR)` ou inférieure à `Q1 - (1.5 * IQR)` est une valeur aberrante.
On va cette fois-ci prendre l'exemple de la profondeur de l'opération.

```{r, message=FALSE, fig.dim=c(7,5), warning=FALSE}
result_profondeur <- test_ope_profondeur(
  data = data_IDF,
  pdf = FALSE,
  csv = FALSE,
  method = 2
  )

```


### C) Interval de confiance

### D) Croisement avec d'autres variables

Certaines variables sont définis en fonction d'autres et on peut vérifier l'une en la croisant avec une autre.  
Par exemple, on sait que la longueur de l'opération est définie par la largeur de l'opération.  
On peut dès lors tracé une tendance et identifier les valeurs aberrantes à partir de celle-ci. Pour cela on va  
prendre l'exemple de la longueur (`test_ope_longeur()`) en choisissant `method = 4`. 

```{r, message=FALSE, fig.dim=c(7,5), warning=FALSE}
result_longueur <- test_ope_Lon(
  data = data_IDF,
  pdf = FALSE,
  csv = FALSE,
  method = 4
  )

```

### E) Résumer des tests

Après avoir réalisé tous les tests souhaités, il est possible de visualiser globalement les résultats des tests :  
(1) Nombre d'alerte par test, (2) Nombre d'alerte par cours d'eau, et (3) Nombre d'alerte par années. Cette  
fonction permet également de créer un tableau regrouppant les résultats de l'ensemble des tests réalisés avec  
deux choix possibles : soit en chargeant les fichiers .csv enregistrés au cours des tests, soit en indiquant les  
noms des tableaux se trouvant dans l'environnement de travail de R.  
Ici on optera plutôt pour la deuxième option.

```{r, message=FALSE, fig.dim=c(7,5), warning=FALSE}
final_result <- join_Testresult(
  data = data_IDF,
  pdf = FALSE,
  csv = FALSE,
  option = 2,
  file.list = c("result_Lar", 
                "result_dist", 
                "result_DS", 
                "result_TempJanv", 
                "result_profondeur", 
                "result_longueur")
  )

```
